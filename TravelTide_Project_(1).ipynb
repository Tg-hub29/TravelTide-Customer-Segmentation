{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tg-hub29/TravelTide-Customer-Segmentation/blob/main/TravelTide_Project_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TravelTide Customer Segmentation Project**"
      ],
      "metadata": {
        "id": "lyS8HbFWPQ85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlalchemy as sa\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from math import radians, sin, cos, sqrt, atan2\n",
        "\n",
        "DB_URL = \"postgresql+psycopg2://Test:bQNxVzJL4g6u@ep-noisy-flower-846766.us-east-2.aws.neon.tech/TravelTide?sslmode=require\"\n",
        "engine = sa.create_engine(DB_URL)\n"
      ],
      "metadata": {
        "id": "bzZ0ueBjZVw2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install fpdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpFhSOtz6_ja",
        "outputId": "d2885972-7485-4342-dee8-3b1cd0986d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=bb2fbe7ef2a8f1172d680b0f890b236d988689c6a7b937ec8bd2eca4f125aedc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/62/11/dc73d78e40a218ad52e7451f30166e94491be013a7850b5d75\n",
            "Successfully built fpdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction & Cleaning with **SQL**"
      ],
      "metadata": {
        "id": "yllOuIoiPJyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql_query = \"\"\"\n",
        "-- Q1: Select sessions after Jan 4, 2023\n",
        "WITH sessions_2023 AS (\n",
        "    SELECT * FROM sessions WHERE session_start > '2023-01-04'\n",
        "),\n",
        "\n",
        "-- Q2: Filter users with more than 7 sessions\n",
        "filtered_users AS (\n",
        "    SELECT user_id\n",
        "    FROM sessions_2023\n",
        "    GROUP BY user_id\n",
        "    HAVING COUNT(*) > 7\n",
        "),\n",
        "\n",
        "-- Q3: Build session base by joining users, flights, and hotels\n",
        "session_base AS (\n",
        "    SELECT\n",
        "        s.session_id, s.user_id, s.trip_id, s.session_start, s.session_end,\n",
        "        EXTRACT(EPOCH FROM s.session_end - s.session_start) AS session_duration,\n",
        "        s.page_clicks, s.flight_discount, s.flight_discount_amount,\n",
        "        s.hotel_discount, s.hotel_discount_amount, s.flight_booked, s.hotel_booked,\n",
        "        s.cancellation, u.birthdate, u.gender, u.married, u.has_children,\n",
        "        u.home_country, u.home_city, u.home_airport,\n",
        "        u.home_airport_lat, u.home_airport_lon, u.sign_up_date,\n",
        "        f.origin_airport, f.destination_airport, f.seats,\n",
        "        f.return_flight_booked, f.departure_time, f.return_time,\n",
        "        f.checked_bags, f.trip_airline, f.destination_airport_lat,\n",
        "        f.destination_airport_lon, f.base_fare_usd, h.hotel_name,\n",
        "        CASE WHEN h.nights < 0 THEN 0 ELSE COALESCE(h.nights, 0) END AS nights,\n",
        "        COALESCE(h.rooms, 1) AS rooms,\n",
        "        h.check_in_time, h.check_out_time,\n",
        "        COALESCE(h.hotel_per_room_usd, 0) AS hotel_price_per_room_night_usd\n",
        "    FROM sessions_2023 s\n",
        "    LEFT JOIN users u ON s.user_id = u.user_id\n",
        "    LEFT JOIN flights f ON s.trip_id = f.trip_id\n",
        "    LEFT JOIN hotels h ON s.trip_id = h.trip_id\n",
        "    WHERE s.user_id IN (SELECT user_id FROM filtered_users)\n",
        "),\n",
        "\n",
        "-- Q4: Aggregate all session + trip behavior per user\n",
        "user_level_agg AS (\n",
        "    SELECT\n",
        "        s.user_id, -- Qualified user_id\n",
        "        COUNT(DISTINCT s.session_id) AS num_sessions,\n",
        "        AVG(COALESCE(s.session_duration, 0)) AS avg_session_duration,\n",
        "        SUM(COALESCE(s.page_clicks, 0)) AS num_clicks,\n",
        "\n",
        "        COALESCE(SUM(CASE WHEN s.cancellation THEN 1 ELSE 0 END), 0) AS sessions_with_cancellation,\n",
        "        COALESCE(SUM(CASE WHEN s.flight_discount THEN 1 ELSE 0 END), 0) AS sessions_with_flight_discount,\n",
        "        COALESCE(SUM(CASE WHEN s.hotel_discount THEN 1 ELSE 0 END), 0) AS sessions_with_hotel_discount,\n",
        "        COALESCE(SUM(CASE WHEN s.flight_booked THEN 1 ELSE 0 END), 0) AS sessions_with_flight_booked,\n",
        "        COALESCE(SUM(CASE WHEN s.hotel_booked THEN 1 ELSE 0 END), 0) AS sessions_with_hotel_booked,\n",
        "\n",
        "        COALESCE(AVG(COALESCE(f.checked_bags, 0)), 0) AS avg_bags, -- Qualified checked_bags and COALESCE AVG result\n",
        "        COALESCE(AVG(COALESCE(s.flight_discount_amount, 0)), 0) AS avg_flight_discount_amount, -- COALESCE AVG result\n",
        "        COALESCE(AVG(COALESCE(s.hotel_discount_amount, 0)), 0) AS avg_hotel_discount_amount, -- COALESCE AVG result\n",
        "\n",
        "        COUNT(DISTINCT s.trip_id) AS num_trips, -- COUNT is usually not null for groups\n",
        "\n",
        "        COALESCE(SUM(CASE WHEN s.flight_booked AND f.return_flight_booked THEN 2\n",
        "                 WHEN s.flight_booked THEN 1 ELSE 0 END), 0) AS num_flights,\n",
        "\n",
        "        COALESCE(AVG(CASE WHEN f.departure_time IS NOT NULL AND s.session_end IS NOT NULL\n",
        "                 THEN EXTRACT(DAY FROM f.departure_time - s.session_end)\n",
        "                 ELSE 0 END), 0) AS time_after_booking_days, -- Qualified departure_time and session_end, COALESCE AVG result\n",
        "\n",
        "        COALESCE(AVG(COALESCE(f.seats, 0)), 0) AS avg_seats_per_flight, -- Qualified seats and COALESCE AVG result\n",
        "        COALESCE(AVG(COALESCE(h.nights, 0)), 0) AS avg_nights_per_hotel_stay, -- Qualified nights and COALESCE AVG result\n",
        "\n",
        "        COALESCE(SUM(COALESCE(f.base_fare_usd, 0)), 0) AS total_flight_fare_usd, -- Qualified base_fare_usd and COALESCE SUM result\n",
        "        SUM(\n",
        "            COALESCE(s.hotel_price_per_room_night_usd, 0) * COALESCE(s.nights, 0) * COALESCE(s.rooms, 1) *\n",
        "            (1 - COALESCE(s.hotel_discount_amount, 0))\n",
        "        ) AS total_hotel_revenue_usd, -- Qualified hotel columns and discount amount, COALESCE SUM result\n",
        "\n",
        "        -- Q5: Distance estimation - calculate in Python\n",
        "        ---Most SQL engines don’t have haversine built-in.\n",
        "\n",
        "        -- Q6: Exploration metric\n",
        "        COALESCE(SUM(CASE WHEN s.flight_booked AND f.destination_airport != u.home_airport THEN 1 ELSE 0 END), 0) AS num_flight_to_new_destination, -- Qualified destination_airport and home_airport, COALESCE SUM result\n",
        "\n",
        "        -- Q7: Seasonal behavior\n",
        "        COALESCE(SUM(CASE WHEN s.flight_booked AND EXTRACT(MONTH FROM f.departure_time) IN (6,7,8) THEN 1 ELSE 0 END), 0) AS num_summer_flights, -- Qualified departure_time, COALESCE SUM result\n",
        "        COALESCE(SUM(CASE WHEN s.hotel_booked AND EXTRACT(MONTH FROM h.check_in_time) IN (12,1,2) THEN 1 ELSE 0 END), 0) AS num_winter_hotel_stays, -- Qualified check_in_time, COALESCE SUM result\n",
        "\n",
        "        -- Q8: Final demographics & user info\n",
        "        COALESCE(MAX(u.birthdate), '1900-01-01') AS birthdate, -- COALESCE with a default date\n",
        "        COALESCE(MAX(u.gender), 'Unknown') AS gender, -- COALESCE with a default string\n",
        "        COALESCE(BOOL_OR(u.married), FALSE) AS married, -- COALESCE with FALSE for boolean\n",
        "        COALESCE(BOOL_OR(u.has_children), FALSE) AS has_children, -- COALESCE with FALSE for boolean\n",
        "        COALESCE(MAX(u.home_country), 'Unknown') AS home_country, -- COALESCE with a default string\n",
        "        COALESCE(MAX(u.home_city), 'Unknown') AS home_city, -- COALESCE with a default string\n",
        "        COALESCE(MAX(u.home_airport), 'Unknown') AS home_airport, -- COALESCE with a default string\n",
        "        COALESCE(MAX(u.home_airport_lat), 0) AS home_airport_lat, -- Qualified lat/lon, COALESCE, include for Python\n",
        "        COALESCE(MAX(u.home_airport_lon), 0) AS home_airport_lon, -- Qualified lat/lon, COALESCE, include for Python\n",
        "        COALESCE(MAX(f.destination_airport_lat), 0) AS avg_destination_airport_lat, -- Qualified lat/lon, retained alias for consistency with Python, COALESCE, include for Python\n",
        "        COALESCE(MAX(f.destination_airport_lon), 0) AS avg_destination_airport_lon, -- Qualified lat/lon, retained alias for consistency with Python, COALESCE, include for Python\n",
        "        COALESCE(MAX(u.sign_up_date), '1900-01-01') AS sign_up_date -- Qualified sign_up_date, COALESCE with a default date\n",
        "-- Nights cannot be negative; default to 0 to avoid inflating stay duration\n",
        "\n",
        "    FROM session_base s\n",
        "    LEFT JOIN users u ON s.user_id = u.user_id\n",
        "    LEFT JOIN flights f ON s.trip_id = f.trip_id\n",
        "    LEFT JOIN hotels h ON s.trip_id = h.trip_id -- Added hotels join for hotel columns\n",
        "    GROUP BY s.user_id -- Qualified user_id in GROUP BY\n",
        ")\n",
        "\n",
        "-- Final selection for export to Python\n",
        "SELECT * FROM user_level_agg;\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FtfjmGgYQaUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the query and load data\n",
        "final_df = pd.read_sql_query(sql_query, con=engine)"
      ],
      "metadata": {
        "id": "tlxGCWRTuxx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows and the shape\n",
        "print(final_df.shape)\n",
        "display(final_df.head())"
      ],
      "metadata": {
        "id": "s9Eq1aW1u2OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_df.isnull().sum())"
      ],
      "metadata": {
        "id": "p5ROGQ5jsbq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "sePOclRivZ6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the nessaarry Libraries for Feauture Engineering\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from fpdf import FPDF\n",
        "from math import radians, sin, cos, sqrt, atan2"
      ],
      "metadata": {
        "id": "LqEQvTJLw4Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert date columns to datetime format\n",
        "final_df['sign_up_date'] = pd.to_datetime(final_df['sign_up_date'])\n",
        "final_df['birthdate'] = pd.to_datetime(final_df['birthdate'])"
      ],
      "metadata": {
        "id": "N-EqMimzw-Vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate age in years and customer age in months\n",
        "final_df['age'] = (datetime(2025, 7, 1) - final_df['birthdate']).dt.days // 365\n",
        "final_df['customer_age_months'] = (datetime(2025, 7, 1) - final_df['sign_up_date']).dt.days // 30\n"
      ],
      "metadata": {
        "id": "imxKqqhDxJj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Proportion of sessions with flight and hotel discounts\n",
        "final_df['flight_discount_proportion'] = final_df['sessions_with_flight_discount'] / final_df['num_sessions']\n",
        "final_df['hotel_discount_proportion'] = final_df['sessions_with_hotel_discount'] / final_df['num_sessions']\n"
      ],
      "metadata": {
        "id": "j8p-ZPYIxR5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Average discount score combining flight and hotel\n",
        "final_df['avg_discount_score'] = final_df[['avg_flight_discount_amount', 'avg_hotel_discount_amount']].mean(axis=1)"
      ],
      "metadata": {
        "id": "aLelIgjSxXfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bargain Index captures both discount usage and spend\n",
        "# → helps identify \"deal-seekers\" vs. \"full-fare\" customers\n",
        "final_df['bargain_index'] = (...)\n",
        "\n",
        "#Bargain Index = proportion * discount * total fare\n",
        "\n",
        "final_df['bargain_index'] = (\n",
        "    final_df['flight_discount_proportion'].fillna(0) *\n",
        "    final_df['avg_flight_discount_amount'].fillna(0) *\n",
        "    final_df['total_flight_fare_usd'].fillna(0)\n",
        ")"
      ],
      "metadata": {
        "id": "odXAU45AxvTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Total revenue (flights + hotel stays)\n",
        "final_df['total_revenue'] = final_df['total_flight_fare_usd'].fillna(0) + final_df['total_hotel_revenue_usd'].fillna(0)\n",
        "\n",
        "#Function to calculate distance between home and destination airports\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371  # Radius of Earth in km\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    return R * c\n"
      ],
      "metadata": {
        "id": "Uha84whPyN30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "7AQAHE-r4vWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exploration Index = % of flights to new destinations\n",
        "final_df['exploration_index'] = final_df['num_flight_to_new_destination'] / final_df['num_flights'].replace(0, np.nan)\n"
      ],
      "metadata": {
        "id": "8rDnICUyy6Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill NaNs for modeling\n",
        "features_df = final_df.fillna(0).copy()"
      ],
      "metadata": {
        "id": "LcEHT3why_Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Selected features for clustering analysis\n",
        "feature_cols = [\n",
        "    'flight_discount_proportion',\n",
        "    'avg_flight_discount_amount',\n",
        "    'exploration_index',\n",
        "    'bargain_index',\n",
        "    'avg_session_duration',\n",
        "    'customer_age_months',\n",
        "]"
      ],
      "metadata": {
        "id": "G7_cX2JSzGhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering with KMeans**\n",
        "\n",
        "* KMeans is an unsupervised learning method that groups customers into K clusters based on behavior similarity.It works by minimizing the distance between points and their assigned cluster centers.I chose it for its simplicity, speed, and effectiveness in customer segmentation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JDCItQPNzRrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "# Select the features for clustering and assign them to X\n",
        "X = features_df[feature_cols]\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "7JaycSwizX_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## KMeans business-friendly fixed groups, fast.\n",
        "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
        "kmeans.fit(X_scaled)"
      ],
      "metadata": {
        "id": "u3oIL2xszmq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df['cluster'] = kmeans.labels_\n",
        "\n",
        "segment_names = {\n",
        "    0: 'Bargain Seekers',\n",
        "    1: 'Family Travelers',\n",
        "    2: 'Loyal Explorers',\n",
        "    3: 'Infrequent Users'\n",
        "}\n",
        "features_df['segment'] = features_df['cluster'].map(segment_names)"
      ],
      "metadata": {
        "id": "kPFHIcKUzt3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize Clusters**\n",
        "\n",
        "* PCA reduces high-dimensional data into 2 components for easy visualization.It captures the directions where the data varies the most.This helps us plot customer segments in 2D without losing much information.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mzODPAmWz6b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)"
      ],
      "metadata": {
        "id": "h5qzSBOhz5wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PCA shape:\", X_pca.shape)\n",
        "print(\"Feature matrix shape:\", X_scaled.shape)\n"
      ],
      "metadata": {
        "id": "ZKwfNVkO1ft1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_df['segment'].value_counts(dropna=False))\n"
      ],
      "metadata": {
        "id": "9YpUcsoR1h6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure cluster labels exist\n",
        "if 'cluster' not in features_df.columns:\n",
        "    features_df['cluster'] = kmeans.labels_\n",
        "\n",
        "# Re-map to segment names\n",
        "segment_names = {\n",
        "    0: 'Bargain Seekers',\n",
        "    1: 'Family Travelers',\n",
        "    2: 'Loyal Explorers',\n",
        "    3: 'Infrequent Users'\n",
        "}\n",
        "features_df['segment'] = features_df['cluster'].map(segment_names)\n"
      ],
      "metadata": {
        "id": "t5_czE4T1mtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom green-gold color palette with more yellow, green, and a dark/black tone\n",
        "green_gold_palette = ['#FFD700', '#32CD32', '#ADFF2F', '#000000', '#FFFF00']"
      ],
      "metadata": {
        "id": "NCI1ddp1AhyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segment_palette = {\n",
        "    'Bargain Seekers': '#7DBE3C',\n",
        "    'Family Travelers': '#FFD700',\n",
        "    'Loyal Explorers': '#4E79A7',\n",
        "    'Infrequent Users': '#B39DDB'\n",
        "}\n"
      ],
      "metadata": {
        "id": "I6ZH3324AK0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid extra spaces, casing issues\n",
        "features_df['segment'] = features_df['segment'].astype(str)\n",
        "\n",
        "# Order by average revenue\n",
        "revenue_order = (\n",
        "    features_df.groupby('segment')['total_revenue']\n",
        "    .mean()\n",
        "    .sort_values(ascending=False)\n",
        "    .index.tolist()\n",
        ")\n"
      ],
      "metadata": {
        "id": "o2yIoNL0BnbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1],hue=features_df['segment'], palette=segment_palette, alpha=0.8)\n",
        "plt.title('Customer Segments (PCA View)')\n",
        "plt.xlabel('PCA 1')\n",
        "plt.ylabel('PCA 2')\n",
        "plt.legend(title='Segment')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zhRbd9JN0MVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='segment', y='total_revenue',hue='segment', data=features_df, estimator=np.mean,\n",
        "            errorbar=None,palette=segment_palette, order=revenue_order,legend=False)\n",
        "plt.title('Average Revenue per Segment')\n",
        "plt.ylabel('Avg Revenue')\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5wXIH5Dv2B7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate order by average avg_flight_discount_amount in descending order\n",
        "discount_order = features_df.groupby('segment')['avg_flight_discount_amount'].mean().sort_values(ascending=False).index\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(\n",
        "    x='segment',\n",
        "    y='avg_flight_discount_amount',\n",
        "    data=features_df,\n",
        "    estimator=np.mean,\n",
        "    errorbar=None,\n",
        "    palette=segment_palette,\n",
        "    hue='segment',\n",
        "    legend=False,\n",
        "    order=discount_order # Add order\n",
        ")\n",
        "plt.title('Average Flight Discount per Segment')\n",
        "plt.ylabel('Avg Flight Discount')\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pSH-8MGp22bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate order by average age in descending order\n",
        "age_order = features_df.groupby('segment')['age'].mean().sort_values(ascending=False).index\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x='segment',y='age',data=features_df,estimator=np.mean,errorbar=None,\n",
        "            palette=segment_palette,hue='segment', legend=False, order=age_order )\n",
        "plt.title('Average Customer Age by Segment')\n",
        "plt.ylabel('Age (Years)')\n",
        "plt.xticks(rotation=15)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oiibg0jQ3dko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_df.columns)       # Does it contain 'segment'?\n",
        "print('segment' in features_df.columns)\n",
        "\n",
        "print(feature_cols)              # Are these column names correct and present in features_df?\n",
        "print(set(feature_cols) - set(features_df.columns))  # Columns missing in features_df\n"
      ],
      "metadata": {
        "id": "fn9fmrQa5hpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_feature_cols = [col for col in feature_cols if col in features_df.columns]\n",
        "segment_summary = features_df.groupby('segment')[valid_feature_cols].mean().round(2)\n",
        "print(segment_summary)\n"
      ],
      "metadata": {
        "id": "PsoavizRSF19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DBSCAN for noise handling**\n",
        "\n",
        "* Why DBSCAN? Unlike KMeans, DBSCAN does not require us to predefine the number of clusters.\n",
        "It groups together points that are close in high-density areas and labels outliers as noise (-1).This method is helpful to detect unusually behaving users or small niche groups.However, DBSCAN was sensitive to parameter tuning and resulted in many points labeled as noise.In our case, it confirmed the core clusters found by KMeans but added noise points that may represent rare behaviors.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dTlZSo8c5krm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DBSCAN - finds niche/outliers, no need to pre-set K.\n",
        "dbscan = DBSCAN(eps=0.6, min_samples=6)\n",
        "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
        "features_df['dbscan_cluster'] = dbscan_labels\n",
        "\n",
        "print(\" DBSCAN label counts (cluster vs noise)\")\n",
        "print(features_df['dbscan_cluster'].value_counts())\n"
      ],
      "metadata": {
        "id": "nSwTrDHt5gxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Unsupervised Method: Hierarchical Clustering(Optional)**"
      ],
      "metadata": {
        "id": "CZDSp-BbTJ80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Why this? It helps understand how data points form clusters at different\n",
        "# distance thresholds it doesn’t require a fixed K like KMeans\n",
        "# Hierarchical reveals segment splits at different levels.\n",
        "import scipy.cluster.hierarchy as sch\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage"
      ],
      "metadata": {
        "id": "AyGrP0-PTJQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create linkage matrix\n",
        "linkage_matrix = linkage(X_scaled, method='ward')"
      ],
      "metadata": {
        "id": "x36tSC6qUAZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot dendrogram\n",
        "plt.figure(figsize=(12, 6))\n",
        "dendrogram(linkage_matrix, truncate_mode='level', p=5)\n",
        "plt.title(\"Hierarchical Clustering Dendrogram (truncated at 5 levels)\")\n",
        "plt.xlabel(\"Data Points\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PInhCz-YUU2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import fcluster\n",
        "# Extract flat cluster labels by cutting the dendrogram at a distance threshold\n",
        "hier_labels = fcluster(linkage_matrix, t=10, criterion='distance')\n",
        "features_df['hier_cluster'] = hier_labels\n"
      ],
      "metadata": {
        "id": "vR2cPTyrmyqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"KMeans Segment Counts\")\n",
        "print(features_df['segment'].value_counts())\n",
        "print(\"Hierarchical Cluster Counts\")\n",
        "print(features_df['hier_cluster'].value_counts())"
      ],
      "metadata": {
        "id": "pgo6b6Q8m3B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by KMeans segments\n",
        "kmeans_summary = features_df.groupby('segment')[['total_revenue', 'bargain_index', 'avg_flight_discount_amount']].mean().round(2)\n",
        "\n",
        "# Group by Hierarchical clusters\n",
        "hier_summary = features_df.groupby('hier_cluster')[['total_revenue', 'bargain_index', 'avg_flight_discount_amount']].mean().round(2)\n",
        "\n",
        "print(\"KMeans Summary\", kmeans_summary)\n",
        "print(\"Hierarchical Summary\", hier_summary)\n"
      ],
      "metadata": {
        "id": "Hq4vRr-QnO4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary**\n",
        "I compared KMeans and Hierarchical clustering to evaluate\n",
        "consistency in customer groupings. While KMeans produced four business-friendly segments, the hierarchical model revealed slightly different groupings based on travel distance and revenue. Overall, both models aligned in identifying a group of discount-driven users and loyal frequent travelers, confirming the robustness of our segmentation."
      ],
      "metadata": {
        "id": "K2mKGL1Rniu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hypothesis Testing: Segment Differences in Revenue & Discount Usage\n",
        "\n"
      ],
      "metadata": {
        "id": "-HI_U0WvPmmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Optional: Drop missing values for cleaner testing\n",
        "df = features_df.dropna(subset=['total_revenue', 'flight_discount_proportion', 'segment'])\n",
        "\n",
        "# Group data by segments\n",
        "segments = df['segment'].unique()\n",
        "\n",
        "# ANOVA for total_revenue\n",
        "revenue_groups = [df[df['segment'] == seg]['total_revenue'] for seg in segments]\n",
        "revenue_stat, revenue_p = f_oneway(*revenue_groups)\n",
        "\n",
        "# ANOVA for flight_discount\n",
        "discount_groups = [df[df['segment'] == seg]['flight_discount_proportion'] for seg in segments]\n",
        "discount_stat, discount_p = f_oneway(*discount_groups)\n",
        "\n",
        "\n",
        "print(\"=== ANOVA: Total Revenue Across Segments ===\")\n",
        "print(f\"F-statistic: {revenue_stat:.2f}, p-value: {revenue_p:.4f}\")\n",
        "if revenue_p < 0.05:\n",
        "    print(\"Statistically significant difference in total revenue between segments.\")\n",
        "else:\n",
        "    print(\"No significant difference in total revenue between segments.\")\n",
        "\n",
        "print(\"\\n=== ANOVA: Discount Usage Across Segments ===\")\n",
        "print(f\"F-statistic: {discount_stat:.2f}, p-value: {discount_p:.4f}\")\n",
        "if discount_p < 0.05:\n",
        "    print(\"Statistically significant difference in discount usage between segments.\")\n",
        "else:\n",
        "    print(\"No significant difference in discount usage between segments.\")\n"
      ],
      "metadata": {
        "id": "DfoMVVwQgVE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "score = silhouette_score(X_scaled, kmeans.labels_)\n",
        "print(\"Silhouette Score (KMeans):\", score)\n"
      ],
      "metadata": {
        "id": "y2W9FXF343j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary for ANOVA TEST**\n",
        "We performed one-way ANOVA tests to evaluate whether there are statistically significant differences between customer segments in terms of total revenue and discount usage.\n",
        "\n",
        "The results show a significant difference in **total revenue** across segments (F = 338.11, p < 0.001), and an even more pronounced difference in **discount usage** (F = 2191.37, p < 0.001). These findings confirm that customer groups behave differently in terms of their spending and responsiveness to discounts — validating the relevance of our segmentation approach and supporting personalized perks for each group.\n"
      ],
      "metadata": {
        "id": "kHli6PJDPySu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(engine, query): ...\n",
        "def feature_engineering(df): ...\n",
        "def run_kmeans(X_scaled, n_clusters=4): ...\n",
        "def run_dbscan(X_scaled, eps=0.6, min_samples=6): ...\n"
      ],
      "metadata": {
        "id": "yOMkY0p85D7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df.to_csv('perk_assignments.csv', index=False)"
      ],
      "metadata": {
        "id": "5-9S7IaKIJwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the CSV file\n",
        "segment_summary.to_csv(\"segment_profiles.csv\")\n",
        "\n",
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", size=12)\n",
        "pdf.cell(200, 10, txt=\"TravelTide - Customer Segment Summary\", ln=1, align=\"C\")\n",
        "\n",
        "for segment, row in segment_summary.iterrows():\n",
        "    pdf.set_font(\"Arial\", 'B', size=12)\n",
        "    pdf.cell(200, 10, txt=f\"\\nSegment: {segment}\", ln=1)\n",
        "    pdf.set_font(\"Arial\", size=11)\n",
        "    for metric, value in row.items():\n",
        "        pdf.multi_cell(0, 8, txt=f\"{metric}: {value}\")\n",
        "\n",
        "pdf.output(\"segment_summary_report.pdf\")\n"
      ],
      "metadata": {
        "id": "FTmh33Z_57bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2usVae8MHOhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export PCA to visualize the cluster scatter plot in Tableau\n",
        "pca_df = pd.DataFrame(X_pca, columns=['pca_1', 'pca_2'])\n",
        "pca_df['segment'] = features_df['segment']\n",
        "pca_df['user_id'] = features_df['user_id']\n",
        "\n",
        "# PCA plot data\n",
        "pca_df.to_csv(\"pca_clusters_for_tableau.csv\", index=False)\n",
        "print(\"Exported pca_clusters_for_tableau.csv.\")\n"
      ],
      "metadata": {
        "id": "3NC4BULp7495"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export data for Tableau analysis\n",
        "tableau_data = features_df.copy()\n",
        "tableau_data.to_csv('tableau_final_data.csv', index=False)\n",
        "\n",
        "print(\"Exported tableau_final_data.csv for Tableau upload.\")"
      ],
      "metadata": {
        "id": "OXbEyI7k7hEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8hKCIH-O_cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in features_df for Tableau:\")\n",
        "print(features_df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "_-I_ISbDy7V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('tableau_final_data.csv')\n",
        "files.download('pca_clusters_for_tableau.csv')\n"
      ],
      "metadata": {
        "id": "Lccunkxp8BIl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}